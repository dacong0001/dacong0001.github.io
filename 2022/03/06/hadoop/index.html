<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Mapper、Reducer，Driver构造步骤Mapper：​    1.extend Mapper&lt;k,v,k,v&gt;,注意出入和输出kv的格式（与java不同注意包）   ​    2.然后重写 map方法，根据源码可知 里面的map方法有几个kv就运行几次所以要把一些创建类的东西放在方法外面。 ​    3.context.write(k,v);，提交时要注意kv的数据类型。">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop">
<meta property="og:url" content="http://example.com/2022/03/06/hadoop/index.html">
<meta property="og:site_name" content="大葱的笔记">
<meta property="og:description" content="Mapper、Reducer，Driver构造步骤Mapper：​    1.extend Mapper&lt;k,v,k,v&gt;,注意出入和输出kv的格式（与java不同注意包）   ​    2.然后重写 map方法，根据源码可知 里面的map方法有几个kv就运行几次所以要把一些创建类的东西放在方法外面。 ​    3.context.write(k,v);，提交时要注意kv的数据类型。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646563177298.png">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646528945437.png">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646471050412.png">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646563186420.png">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646563193170.png">
<meta property="og:image" content="http://example.com/1646470491592.png">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646563201262.png">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646563207533.png">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646563211839.png">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646563217632.png">
<meta property="og:image" content="http://example.com/1646472095363.png">
<meta property="og:image" content="http://example.com/1646472279827.png">
<meta property="og:image" content="http://example.com/1646472445540.png">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646563228969.png">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646563236218.png">
<meta property="og:image" content="http://example.com/1646529956381.png">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646563282412.png">
<meta property="og:image" content="http://example.com/2022/03/06/hadoop/1646563292818.png">
<meta property="article:published_time" content="2022-03-06T10:45:28.926Z">
<meta property="article:modified_time" content="2022-03-06T12:53:20.005Z">
<meta property="article:author" content="Dacong001">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/03/06/hadoop/1646563177298.png">

<link rel="canonical" href="http://example.com/2022/03/06/hadoop/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Hadoop | 大葱的笔记</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">大葱的笔记</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">大数据</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/03/06/hadoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dacong001">
      <meta itemprop="description" content="菜鸡的学习过程">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大葱的笔记">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2022-03-06 18:45:28 / 修改时间：20:53:20" itemprop="dateCreated datePublished" datetime="2022-03-06T18:45:28+08:00">2022-03-06</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="Mapper、Reducer，Driver构造步骤"><a href="#Mapper、Reducer，Driver构造步骤" class="headerlink" title="Mapper、Reducer，Driver构造步骤"></a>Mapper、Reducer，Driver构造步骤</h3><h4 id="Mapper："><a href="#Mapper：" class="headerlink" title="Mapper："></a>Mapper：</h4><p>​    1.extend Mapper&lt;k,v,k,v&gt;,注意出入和输出kv的格式（<font color='red'>与java不同注意包</font>）  </p>
<p>​    2.然后重写 map方法，根据源码可知 里面的map方法有几个kv就运行几次所以要把一些创建类的东西放在方法外面。</p>
<p>​    3.context.write(k,v);，提交时要注意kv的数据类型。</p>
<h4 id="Reducer："><a href="#Reducer：" class="headerlink" title="Reducer："></a>Reducer：</h4><p>​    1.extend Reducer&lt;kv,v,k,v&gt;,注意出入和输出kv的格式（与java不同注意包）  </p>
<p>​    2.然后重写 reduce方法，根据源码可知 里面的reduce方法会根据value的个数来运行几次所以要把一些创建类的东西放在方法外面。</p>
<p>​    3.context.write(k,v);，提交时要注意kv的数据类型。</p>
<h4 id="Driver："><a href="#Driver：" class="headerlink" title="Driver："></a>Driver：</h4><p>​    1.获取Job对象</p>
<p>​    2.关联Driver类</p>
<p>​    3.关联Mapper类与关联Reducer类</p>
<p>​    4.设置Map的KV类型</p>
<p>​    5.设置最终输出的KV类型</p>
<p>​    6.设置程序的输入输出文件路径</p>
<p>​    7.提交Job</p>
<p><strong>MapTask并行度决定机制</strong></p>
<p><strong>数据块：</strong>Block是HDFS物理上把数据分成一块一块。数据块是HDFS存储数据单位。</p>
<p><strong>数据切片：</strong>数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。数据切片是MapReduce程序计算输入数据的单位，一个切片会对应启动一个MapTask。</p>
<img src="/2022/03/06/hadoop/1646563177298.png" class="" width="1646563177298">

<p>​    如果分为100M的话 DataNode2还要从 1 中获取 28M与自己的100M进行合并运算，中间有传输时间和合并时间，效率低，所以要根据块的大小来设置切片大小。</p>
<h3 id="Job提交流程源码详解"><a href="#Job提交流程源码详解" class="headerlink" title="Job提交流程源码详解"></a><strong>Job提交流程源码详解</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">waitForCompletion()</span><br><span class="line"></span><br><span class="line">submit();</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">// 1建立连接</span><br><span class="line"></span><br><span class="line">​	connect();	</span><br><span class="line"></span><br><span class="line">​		// 1）创建提交Job的代理</span><br><span class="line"></span><br><span class="line">​		new Cluster(getConfiguration());</span><br><span class="line"></span><br><span class="line">​			// （1）判断是本地运行环境还是yarn集群运行环境</span><br><span class="line"></span><br><span class="line">​			initialize(jobTrackAddr, conf);   //返回0是本地  1是yarn</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">// 2 提交job</span><br><span class="line"></span><br><span class="line">submitter.submitJobInternal(Job.this, cluster)</span><br><span class="line"></span><br><span class="line"> 	首先检察输出路径是否存在（会抛出异常 1.为空（没有填写输出路径），2.路径存在）</span><br><span class="line"></span><br><span class="line">​	// 1）创建给集群提交数据的Stag路径（临时缓存路径）</span><br><span class="line"></span><br><span class="line">​	Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	// 2）获取jobId（每一个job都有一个id） ，并创建Job路径  在上一步的Stag路径后加上jobID</span><br><span class="line"></span><br><span class="line">​	JobID jobId = submitClient.getNewJobID();</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	// 3）拷贝jar包到集群</span><br><span class="line"></span><br><span class="line">	copyAndConfigureFiles(job, submitJobDir);	 //本地模式不会提交jar  集群模式会提交</span><br><span class="line"></span><br><span class="line">	rUploader.uploadFiles(job, jobSubmitDir);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	// 4）计算切片，生成切片规划文件</span><br><span class="line"></span><br><span class="line">​		writeSplits(job, submitJobDir);</span><br><span class="line"></span><br><span class="line">​		maps = writeNewSplits(job, jobSubmitDir);   //根据切片信息生产几个mapTask</span><br><span class="line"></span><br><span class="line">​		input.getSplits(job);      //把切片信息保存到 jobID路径</span><br><span class="line">	根基切片个数生成几个map   并把切片信息以log方式输出，在执行日志中也可以看见</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">​	// 5）向Stag路径写XML配置文件</span><br><span class="line"></span><br><span class="line">writeConf(conf, submitJobFile);    //任然保存到JobID下的路径 </span><br><span class="line"></span><br><span class="line">​	conf.writeXml(out); </span><br><span class="line"></span><br><span class="line">​	// 6）提交Job,返回提交状态</span><br><span class="line"></span><br><span class="line">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br><span class="line">//提交完毕后会将刚才生产的缓存文件删除	</span><br></pre></td></tr></table></figure>

<p>最终提交信息为：</p>
<img src="/2022/03/06/hadoop/1646528945437.png" class="" width="1646528945437">

<img src="/2022/03/06/hadoop/1646471050412.png" class="" width="1646471050412">

<img src="/2022/03/06/hadoop/1646563186420.png" class="" width="1646563186420">

<img src="/2022/03/06/hadoop/1646563193170.png" class="" width="1646563193170">

<p>minSize &#x3D; 1; maxSize &#x3D; long的最大值    bolckSize &#x3D; 128m  （在本地运行为32m）</p>
<p><strong>TextInputFormat</strong></p>
<p>​        TextInputFormat是默认的FileInputFormat实现类。按行读取每条记录。键是存储该行在整个文件中的起始字节偏移量， LongWritable类型。值是这行的内容，不包括任何行终止符（换行符和回车符），Text类型。</p>
<p><img src="/1646470491592.png" alt="1646470491592"></p>
<h3 id="CombineTextInputFormat切片机制"><a href="#CombineTextInputFormat切片机制" class="headerlink" title="CombineTextInputFormat切片机制"></a><strong>CombineTextInputFormat</strong>切片机制</h3><p>​    CombineTextInputFormat用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个MapTask处理。</p>
<p><strong>虚拟存储切片最大值设置：</strong><font color='cornflowerblue'>CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);&#x2F;&#x2F; 4m</font></p>
<p><font color='orange'>注意：虚拟存储切片最大值设置最好根据实际的小文件大小情况来设置具体的值。</font></p>
<p><strong>切片机制：</strong></p>
<p>​    生成切片过程包括：虚拟存储过程和切片过程二部分。</p>
<img src="/2022/03/06/hadoop/1646563201262.png" class="" width="1646563201262">

<h4 id="虚拟存储过程："><a href="#虚拟存储过程：" class="headerlink" title="虚拟存储过程："></a>虚拟存储过程：</h4><p>​    将输入目录下所有文件大小，依次和设置的setMaxInputSplitSize值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件均分成2个虚拟存储块（防止出现太小切片）。</p>
<p>​    例如setMaxInputSplitSize值为4M，输入文件大小为8.02M，则先逻辑上分成一个4M。剩余的大小为4.02M，如果按照4M逻辑划分，就会出现0.02M的小的虚拟存储文件，所以将剩余的4.02M文件切分成（2.01M和2.01M）两个文件。</p>
<p><strong>例：</strong></p>
<p>​    输入数据为4个小文件，在不经过任何处理运行时切片个数为4个，当在Driver中增加<code>CombineTextInputFormat.setMaxInputSplitSize(job, 4194304); </code>时，切片个数为为3个</p>
<p>当将大小改为 20971520（20m）时切片各个变为1个。只产生一个MapTask提高了效率。</p>
<h3 id="MapReduce工作流程"><a href="#MapReduce工作流程" class="headerlink" title="MapReduce工作流程"></a>MapReduce工作流程</h3><img src="/2022/03/06/hadoop/1646563207533.png" class="" width="1646563207533">

<img src="/2022/03/06/hadoop/1646563211839.png" class="" width="1646563211839">

<p>上面的流程是整个MapReduce最全工作流程，但是Shuffle过程只是从第7步开始到第16步结束，具体Shuffle过程详解，如下：</p>
<p>（1）MapTask收集我们的map()方法输出的kv对，放到内存缓冲区中</p>
<p>（2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</p>
<p>（3）多个溢出文件会被合并成大的溢出文件</p>
<p>（4）在溢出过程及合并的过程中，都要调用Partitioner进行分区和针对key进行排序</p>
<p>（5）ReduceTask根据自己的分区号，去各个MapTask机器上取相应的结果分区数据</p>
<p>（6）ReduceTask会抓取到同一个分区的来自不同MapTask的结果文件，ReduceTask会将这些文件再进行合并（归并排序）</p>
<p>（7）合并成大文件后，Shuffle的过程也就结束了，后面进入ReduceTask的逻辑运算过程（从文件中取出一个一个的键值对Group，调用用户自定义的reduce()方法）</p>
<p><strong>注意：</strong></p>
<p>（1）Shuffle中的缓冲区大小会影响到MapReduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快。</p>
<p>（2）缓冲区的大小可以通过参数调整，参数：mapreduce.task.io.sort.mb默认100M。</p>
<p><strong>Map 方法之后，Reduce 方法之前的数据处理过程称之为 Shuffer</strong></p>
<img src="/2022/03/06/hadoop/1646563217632.png" class="" width="1646563217632">

<h3 id="Partition分区"><a href="#Partition分区" class="headerlink" title="Partition分区"></a>Partition分区</h3><p>​    默认分区是根据key的hashCode对ReduceTasks个数取模得到的。用户没法控制哪个key存储到哪个分区。</p>
<p><img src="/1646472095363.png" alt="1646472095363"></p>
<p>!<img src="/1646472279827.png" alt="1646472279827">(1646472264084.png)</p>
<p><strong>KV设置为map输出的KV</strong></p>
<h4 id="分区总结"><a href="#分区总结" class="headerlink" title="分区总结"></a>分区总结</h4><ol>
<li><p>如果RedhceTask的数量 &gt; getPantition的结果数，则会多产生几个空的输出文件part-r-000xx;</p>
</li>
<li><p>如果1 &lt; ReduceTask的数量 &lt; getPartition的结果数，则有一部分分区数据无处安放，会Exception;</p>
</li>
<li><p>如果ReduceTask的数量 &#x3D; 1，<strong>不执行分区操作，在执行之前首先要判断ReduceTas数量是否为1</strong>最终结果都交给这一个ReduceTask，最终也就只会产生一个结果文件part-r-00000;</p>
</li>
<li><p>分区号必须从零开始，逐一累加。</p>
<p><img src="/1646472445540.png" alt="1646472445540"></p>
</li>
</ol>
<h3 id="WritableComparable排序"><a href="#WritableComparable排序" class="headerlink" title="WritableComparable排序"></a>WritableComparable排序</h3><img src="/2022/03/06/hadoop/1646563228969.png" class="" width="1646563228969">

<ol>
<li>部分排序<br>MapReduce根据输入记录的键对数据集排序。保证输出的每个文件内部有序。</li>
<li>全排序<br>最终输出结果只有一个文件，且文件内部有序。实现方式是只设置一个ReduceTask。但该方法在处理大型文件时效率极低，因为一台机器处理所有文件，完全丧失了MapReduce所提供的并行架构。</li>
<li>辅助排序:(GroupingComparator分组)<br>在Reduce端对key进行分组。应用于:在接收的key为bean对象时，想让一个或几个字段相同（全部<br>字段比较不相同)的key进入到同一个reduce方法时，可以采用分组排序。</li>
<li>二次排序<br>在自定义排序过程中，如果compareTo中的判断条件为两个即为二次排序。</li>
</ol>
<h3 id="Combiner合并"><a href="#Combiner合并" class="headerlink" title="Combiner合并"></a><strong>Combiner合并</strong></h3><ol>
<li><p>Combiner是MR程序中Mapper和Reducer之外的一种组件。</p>
</li>
<li><p>Combiner组件的父类就是Redicer。</p>
</li>
<li><p>Combiner和Reducen的区别在于运行的位置Combiner是在每一个MapTask所在的节点运行;Reducer是接收全局所有Mappen的输出结果;</p>
<p>Combiner的意义就是对每一个MapTask的输出进行局部汇总，以减小网络传输量。</p>
</li>
<li><p>Combiner能够应用的前提是不能影响最终的业务逻辑，而且，Combiner的输出kv应该跟Reducer的输入kv类型要对应起来。</p>
</li>
</ol>
<p><strong>！！！求平均值的情况不能用Combiner 会导致结果不正确。</strong></p>
<p>求和时可以利用Combiner</p>
<p><em><strong>Combiner主要是作为一个小型的Redicer在每一个MapTask上进行求和计算，从而减少数据传输导致的时间过长</strong></em></p>
<h3 id="OutputFormat数据输出"><a href="#OutputFormat数据输出" class="headerlink" title="OutputFormat数据输出"></a>OutputFormat数据输出</h3><p>   默认输出格式为TextOutputFormat   一行一行写到text文件中</p>
<h5 id="自定义OutputFormat类"><a href="#自定义OutputFormat类" class="headerlink" title="自定义OutputFormat类"></a>自定义OutputFormat类</h5><ul>
<li>自定义一个类继承FileOutputFormat。</li>
<li>改RecordWriter，具体改写方法write（）</li>
</ul>
<p><strong>方法：</strong></p>
<ul>
<li>​    自定义MyFileOutputFormat类后重写getRecordWriter()函数，设置返回值的类型为KV,向自定义MYRecordWriter类传递job。</li>
<li>​    在构造函数中获取传来的job，定义输出流（写出路径），重写writer&lt;K,V&gt;方法，根据条件选择输出流。</li>
<li>​    在close（）方法中关闭创建的输出流。</li>
</ul>
<h3 id="MapReduce内核源码解析"><a href="#MapReduce内核源码解析" class="headerlink" title="MapReduce内核源码解析"></a>MapReduce内核源码解析</h3><h4 id="MapTask工作机制"><a href="#MapTask工作机制" class="headerlink" title="MapTask工作机制"></a>MapTask工作机制</h4><img src="/2022/03/06/hadoop/1646563236218.png" class="" width="1646563236218">

<ul>
<li><font color='red'>Read阶段</font>：MapTask通过InputFormat获得的RecordReader，从输入InputSplit中解析出一个个key&#x2F;value。</li>
<li><font color='red'>Map阶段</font>：该节点主要是将解析出的key&#x2F;value交给用户编写map()函数处理，并产生一系列新的key&#x2F;value。</li>
<li><font color='red'>Collect收集阶段</font>：在用户编写map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的key&#x2F;value分区（调用Partitioner），并写入一个环形内存缓冲区中。</li>
<li><font color='red'>Spill阶段</font>：即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</li>
</ul>
<p>溢写阶段详情：</p>
<p>​    步骤1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号Partition进行排序，然后按照key进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照key有序。</p>
<p>​    步骤2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件output&#x2F;spillN.out（N表示当前溢写次数）中。如果用户设置了Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。</p>
<p>​    步骤3：将分区数据的元信息写到内存索引数据结构SpillRecord中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过1MB，则将内存索引写到文件output&#x2F;spillN.out.index中。</p>
<ul>
<li><p><font color='red'>Merge阶段</font>：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</p>
<p>​    当所有数据处理完后，MapTask会将所有临时文件合并成一个大文件，并保存到文件output&#x2F;file.out中，同时生成相应的索引文件output&#x2F;file.out.index。</p>
<p>​    在进行文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的式。每轮合并mapreduce.task.io.sort.factor（默认10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p>
<p>​    让每个MapTask最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p>
</li>
</ul>
<h4 id="ReduceTask工作机制"><a href="#ReduceTask工作机制" class="headerlink" title="ReduceTask工作机制"></a><strong>ReduceTask工作机制</strong></h4><p><img src="/1646529956381.png" alt="img"></p>
<ol>
<li>Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</li>
<li>Sort阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可。</li>
<li>Reduce阶段：reduce()函数将计算结果写到HDFS上。</li>
</ol>
<h4 id="ReduceTask并行度决定机制"><a href="#ReduceTask并行度决定机制" class="headerlink" title="ReduceTask并行度决定机制"></a>ReduceTask并行度决定机制</h4><p>****回顾：****MapTask并行度由切片个数决定，切片个数由输入文件和切片规则决定。</p>
<p>****思考：****ReduceTask并行度由谁决定？</p>
<p>ReduceTask数量的决定是可以直接手动设置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 默认值是1，手动设置为4</span><br><span class="line">job.setNumReduceTasks(4);</span><br></pre></td></tr></table></figure>

<img src="/2022/03/06/hadoop/1646563282412.png" class="" width="1646563282412">

<h3 id="Join-应用"><a href="#Join-应用" class="headerlink" title="Join 应用"></a><strong>Join</strong> <strong>应用</strong></h3><h4 id="Reduce-Join"><a href="#Reduce-Join" class="headerlink" title="Reduce Join"></a><strong>Reduce Join</strong></h4><p>​    Map 端的主要工作：为来自不同表或文件的 key&#x2F;value 对，打标签以区别不同来源的记 </p>
<p>录。然后用连接字段作为 key，其余部分和新加的标志作为 value，最后进行输出。 </p>
<p>​     Reduce 端的主要工作：在 Reduce 端以连接字段作为 key 的分组已经完成，我们只需要 </p>
<p>在每一个分组当中将那些来源于不同文件的记录（在 Map 阶段已经打标志）分开，最后进 </p>
<p>行合并.</p>
<h4 id="Map-Join"><a href="#Map-Join" class="headerlink" title="Map Join"></a><strong>Map Join</strong></h4><p><strong>1</strong>）使用场景</p>
<p>Map Join 适用于一张表十分小、一张表很大的场景。 </p>
<p><strong>2</strong>）优点</p>
<p>思考：在 Reduce 端处理过多的表，非常容易产生数据倾斜。怎么办？ </p>
<p>在 Map 端缓存多张表，提前处理业务逻辑，这样增加 Map 端业务，减少 Reduce 端数 </p>
<p>据的压力，尽可能的减少数据倾斜。 </p>
<p><strong>3</strong>）具体办法：采用 <strong>DistributedCache</strong> </p>
<p>（1）在 Mapper 的 setup 阶段，将文件读取到缓存集合中。 </p>
<p>（2）在 Driver 驱动类中加载缓存。 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//缓存普通文件到 Task 运行节点。</span><br><span class="line">job.addCacheFile(new URI(&quot;file:///e:/cache/pd.txt&quot;));</span><br><span class="line">//如果是集群运行,需要设置 HDFS 路径</span><br><span class="line">job.addCacheFile(new URI(&quot;hdfs://hadoop102:8020/cache/pd.txt&quot;));</span><br></pre></td></tr></table></figure>

<h3 id="ETL"><a href="#ETL" class="headerlink" title="ETL"></a>ETL</h3><p>数据清洗往往在map阶段就实现了，不需要reduce阶段 ，如果只需要数据清洗可以将reducetask设置为0个</p>
<h3 id="MapReduce-开发总结"><a href="#MapReduce-开发总结" class="headerlink" title="MapReduce 开发总结"></a><strong>MapReduce</strong> <strong>开发总结</strong></h3><p>1.输入数据接口：<strong>InputFormat</strong> </p>
<p>​    （1）默认使用的实现类是：TextInputFormat </p>
<p>​    （2）TextInputFormat 的功能逻辑是：一次读一行文本，然后将该行的起始偏移量作为 key，行内容作为 value 返回。 </p>
<p>​    （3）CombineTextInputFormat 可以把多个小文件合并成一个切片处理，提高处理效率。 </p>
<p>2.逻辑处理接口：<strong>Mapper</strong>  </p>
<p>​    用户根据业务需求实现其中三个方法： setup() map() cleanup ()  </p>
<p><strong>3.Partitioner</strong> <strong>分区</strong> </p>
<p>​    （1）有默认实现 HashPartitioner，逻辑是根据 key 的哈希值和 numReduces 来返回一个分区号；key.hashCode()&amp;Integer.MAXVALUE % numReduces </p>
<p>​    （2）如果业务上有特别的需求，可以自定义分区。 </p>
<p><strong>4.Comparable</strong> <strong>排序</strong></p>
<p>​    （1）当我们用自定义的对象作为 key 来输出时，就必须要实现 WritableComparable 接口，重写其中的 compareTo()方法。 </p>
<p>​    （2）部分排序：对最终输出的每一个文件进行内部排序。 </p>
<p>​    （3）全排序：对所有数据进行排序，通常只有一个 Reduce。 </p>
<p>​    （4）二次排序：排序的条件有两个。 </p>
<p><strong>5.Combiner</strong> <strong>合并</strong> </p>
<p>​    Combiner 合并可以提高程序执行效率，减少 IO 传输。但是使用时必须不能影响原有的业务处理结果。 </p>
<p>6.逻辑处理接口：<strong>Reducer</strong> </p>
<p>​    用户根据业务需求实现其中三个方法：reduce() setup() cleanup ()  </p>
<p>7.输出数据接口：<strong>OutputFormat</strong> </p>
<p>​    （1）默认实现类是 TextOutputFormat，功能逻辑是：将每一个 KV 对，向目标文本文件输出一行。 </p>
<p>​    （2）用户还可以自定义 OutputFormat。 </p>
<h3 id="Hadoop-数据压缩"><a href="#Hadoop-数据压缩" class="headerlink" title="Hadoop 数据压缩"></a><strong>Hadoop</strong> <strong>数据压缩</strong></h3><h4 id="压缩的好处和坏处："><a href="#压缩的好处和坏处：" class="headerlink" title="压缩的好处和坏处："></a><strong>压缩的好处和坏处：</strong></h4><p>​    压缩的优点：以减少磁盘 IO、减少磁盘存储空间。 </p>
<p>​    压缩的缺点：增加 CPU 开销。</p>
<h4 id="压缩原则："><a href="#压缩原则：" class="headerlink" title="压缩原则："></a><strong>压缩原则：</strong></h4><p>​    （1）运算密集型的 Job，少用压缩 </p>
<p>​    （2）IO 密集型的 Job，多用压缩 </p>
<h4 id="压缩方式选："><a href="#压缩方式选：" class="headerlink" title="压缩方式选："></a><strong>压缩方式选：</strong></h4><p>​    压缩方式选择时重点考虑：<strong>压缩&#x2F;解压缩速度、压缩率（压缩后存储大小）、压缩后是否可以支持切片</strong>。</p>
<h4 id="压缩位置选择："><a href="#压缩位置选择：" class="headerlink" title="压缩位置选择："></a><strong>压缩位置选择：</strong></h4><p>​    压缩可以在 MapReduce 作用的任意阶段启用。 </p>
<img src="/2022/03/06/hadoop/1646563292818.png" class="" width="1646563292818">

<table>
<thead>
<tr>
<th>压缩格式</th>
<th>对应的编码&#x2F;解码器</th>
</tr>
</thead>
<tbody><tr>
<td>DEFLATE</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
</tr>
<tr>
<td>gzip</td>
<td>org.apache.hadoop.io.compress.GzipCodec</td>
</tr>
<tr>
<td>bzip2</td>
<td>org.apache.hadoop.io.compress.BZip2Codec</td>
</tr>
<tr>
<td>LZO</td>
<td>com.hadoop.compression.lzo.LzopCodec</td>
</tr>
<tr>
<td>Snappy</td>
<td>org.apache.hadoop.io.compress.SnappyCodec</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>参数</th>
<th>默认值</th>
<th>阶段</th>
<th>建议</th>
</tr>
</thead>
<tbody><tr>
<td>io.compression.codecs  （在core-site.xml中配置）</td>
<td>无，这个需要在命令行输入hadoop checknative查看</td>
<td>输入压缩</td>
<td>Hadoop使用文件扩展名判断是否支持某种编解码器</td>
</tr>
<tr>
<td>mapreduce.map.output.compress（在mapred-site.xml中配置）</td>
<td>false</td>
<td>mapper输出</td>
<td>这个参数设为true启用压缩</td>
</tr>
<tr>
<td>mapreduce.map.output.compress.codec（在mapred-site.xml中配置）</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
<td>mapper输出</td>
<td>企业多使用LZO或Snappy编解码器在此阶段压缩数据</td>
</tr>
<tr>
<td>mapreduce.output.fileoutputformat.compress（在mapred-site.xml中配置）</td>
<td>false</td>
<td>reducer输出</td>
<td>这个参数设为true启用压缩</td>
</tr>
<tr>
<td>mapreduce.output.fileoutputformat.compress.codec（在mapred-site.xml中配置）</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
<td>reducer输出</td>
<td>使用标准工具或者编解码器，如gzip和bzip2</td>
</tr>
</tbody></table>
<h4 id="压缩实例"><a href="#压缩实例" class="headerlink" title="压缩实例"></a>压缩实例</h4><p>都在Driver里进行设置</p>
<p>​    在map阶段压缩要在 conf创建后进行设置</p>
<p>​    在reduce阶段压缩要在设置输入输出路径后设置</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/03/06/Hadoop%EF%BC%88%E7%94%9F%E4%BA%A7%E8%B0%83%E4%BC%98%E6%89%8B%E5%86%8C%EF%BC%89/" rel="prev" title="Hadoop 生产调优手册">
      <i class="fa fa-chevron-left"></i> Hadoop 生产调优手册
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/03/06/hello/" rel="next" title="链表，二叉树">
      链表，二叉树 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Mapper%E3%80%81Reducer%EF%BC%8CDriver%E6%9E%84%E9%80%A0%E6%AD%A5%E9%AA%A4"><span class="nav-number">1.</span> <span class="nav-text">Mapper、Reducer，Driver构造步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Mapper%EF%BC%9A"><span class="nav-number">1.1.</span> <span class="nav-text">Mapper：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Reducer%EF%BC%9A"><span class="nav-number">1.2.</span> <span class="nav-text">Reducer：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Driver%EF%BC%9A"><span class="nav-number">1.3.</span> <span class="nav-text">Driver：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Job%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3"><span class="nav-number">2.</span> <span class="nav-text">Job提交流程源码详解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CombineTextInputFormat%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6"><span class="nav-number">3.</span> <span class="nav-text">CombineTextInputFormat切片机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%EF%BC%9A"><span class="nav-number">3.1.</span> <span class="nav-text">虚拟存储过程：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="nav-number">4.</span> <span class="nav-text">MapReduce工作流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Partition%E5%88%86%E5%8C%BA"><span class="nav-number">5.</span> <span class="nav-text">Partition分区</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E6%80%BB%E7%BB%93"><span class="nav-number">5.1.</span> <span class="nav-text">分区总结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#WritableComparable%E6%8E%92%E5%BA%8F"><span class="nav-number">6.</span> <span class="nav-text">WritableComparable排序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Combiner%E5%90%88%E5%B9%B6"><span class="nav-number">7.</span> <span class="nav-text">Combiner合并</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OutputFormat%E6%95%B0%E6%8D%AE%E8%BE%93%E5%87%BA"><span class="nav-number">8.</span> <span class="nav-text">OutputFormat数据输出</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89OutputFormat%E7%B1%BB"><span class="nav-number">8.0.1.</span> <span class="nav-text">自定义OutputFormat类</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E5%86%85%E6%A0%B8%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90"><span class="nav-number">9.</span> <span class="nav-text">MapReduce内核源码解析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MapTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">9.1.</span> <span class="nav-text">MapTask工作机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ReduceTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">9.2.</span> <span class="nav-text">ReduceTask工作机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ReduceTask%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%86%B3%E5%AE%9A%E6%9C%BA%E5%88%B6"><span class="nav-number">9.3.</span> <span class="nav-text">ReduceTask并行度决定机制</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Join-%E5%BA%94%E7%94%A8"><span class="nav-number">10.</span> <span class="nav-text">Join 应用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Reduce-Join"><span class="nav-number">10.1.</span> <span class="nav-text">Reduce Join</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Map-Join"><span class="nav-number">10.2.</span> <span class="nav-text">Map Join</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ETL"><span class="nav-number">11.</span> <span class="nav-text">ETL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce-%E5%BC%80%E5%8F%91%E6%80%BB%E7%BB%93"><span class="nav-number">12.</span> <span class="nav-text">MapReduce 开发总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop-%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9"><span class="nav-number">13.</span> <span class="nav-text">Hadoop 数据压缩</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E7%9A%84%E5%A5%BD%E5%A4%84%E5%92%8C%E5%9D%8F%E5%A4%84%EF%BC%9A"><span class="nav-number">13.1.</span> <span class="nav-text">压缩的好处和坏处：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E5%8E%9F%E5%88%99%EF%BC%9A"><span class="nav-number">13.2.</span> <span class="nav-text">压缩原则：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E6%96%B9%E5%BC%8F%E9%80%89%EF%BC%9A"><span class="nav-number">13.3.</span> <span class="nav-text">压缩方式选：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E4%BD%8D%E7%BD%AE%E9%80%89%E6%8B%A9%EF%BC%9A"><span class="nav-number">13.4.</span> <span class="nav-text">压缩位置选择：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E5%AE%9E%E4%BE%8B"><span class="nav-number">13.5.</span> <span class="nav-text">压缩实例</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Dacong001</p>
  <div class="site-description" itemprop="description">菜鸡的学习过程</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Dacong001</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
